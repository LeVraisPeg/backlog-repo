# Rapport journalier – Développement & Conception  
**Date :** 12/05/2025  

## Objectif de la journée  
L’objectif principal de cette séance était de poursuivre les travaux autour de la **confidentialité différentielle**, d’optimiser le **traitement des données côté Quarkus**, et de **renforcer le moteur de recommandation** à travers des approches SVD et Deep Learning.  

---

## Déroulement de la séance  

### 1. Confidentialité différentielle – Implémentation manuelle des mécanismes  
Dans un souci de **contrôle plus fin** et d’**indépendance vis-à-vis de bibliothèques tierces**, nous avons implémenté **manuellement** deux mécanismes classiques de confidentialité différentielle :  
- **Ajout de bruit Laplacien**  
- **Ajout de bruit Gaussien**  
Ces méthodes ont été codées sans recourir à `diffprivlib`, ce qui nous a permis de mieux comprendre les paramètres d’ε (epsilon) et σ (sigma), et de personnaliser le niveau de bruit selon les cas d’usage.  

En parallèle, nous avons introduit un **mécanisme exponentiel** permettant de faire un **choix aléatoire de données** de manière privée, tout en respectant les garanties théoriques de la differential privacy.  

---

### 2. Optimisation des imports – Multithreading & réduction des appels réseau  
Afin de réduire la charge et d’accélérer l’importation des jeux de données volumineux (films, avis, tags), plusieurs optimisations ont été introduites :  
- Mise en place d’un **traitement multithreadé** pour paralléliser l’importation des fichiers CSV  
- Refactorisation des appels REST vers Quarkus pour **regrouper les données par paquets**, et ainsi limiter le nombre de requêtes  
- Réduction des appels unitaires en **structurant les payloads en batchs** cohérents, améliorant ainsi les performances et la stabilité de l'import  

Ces ajustements ont significativement amélioré la **vitesse d’injection des données** et réduit les **temps de latence réseau**.  

---

### 3. Moteur de recommandation – SVD & Deep Learning  
Sur la partie **recommandation**, nous avons entamé deux axes complémentaires :  
- Intégration d’un algorithme de **SVD (Singular Value Decomposition)** comme base pour un système de recommandation collaboratif  
- Lancement du développement côté **serveur Python**, avec une première structure pour accueillir un **modèle de Deep Learning** dédié à la prédiction des préférences utilisateurs  

Le serveur Python a été initialisé avec une API REST simple, et les premières briques du **modèle neuronal** ont été posées (choix des couches, normalisation des données, etc.).

---

## Bilan de la journée  
Cette journée a permis de **renforcer à la fois la confidentialité, la performance et l’intelligence du système** :  
- La confidentialité différentielle est maintenant **maîtrisée en interne**, avec une base de code propre et flexible  
- L’importation des données est **plus rapide et plus efficace**, grâce au multithreading et à la réduction des appels réseau  
- Le **moteur de recommandation évolue** vers une solution hybride SVD / Deep Learning prometteuse  

Ces progrès techniques sont essentiels pour garantir à la fois la **sécurité, la scalabilité et la pertinence** du système de recommandation.
