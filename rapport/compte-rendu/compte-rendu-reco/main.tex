\documentclass{article}
\usepackage{amsmath, amssymb, geometry}
\usepackage{tikz}
\usepackage{titlesec}
\usepackage{lmodern}
\usepackage[french]{babel}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor} % pour la couleur (optionnel)
\usepackage{graphicx}
\usepackage{rotating}

\lstset{
  language=Python,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  showstringspaces=false,
  frame=single
}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\geometry{a4paper, margin=2.5cm}
\date{\vspace{1cm} \today}

\begin{document}

\begin{titlepage}
    \centering
    \begin{tikzpicture}[remember picture, overlay]
        \node[opacity=0.1] at (current page.center) {\includegraphics[width=\paperwidth,height=\paperheight,keepaspectratio]{image.png}};
    \end{tikzpicture}

    \vspace*{2cm}

    % Titre principal
    {\Huge\bfseries Compte Rendu de Projet\\[0.5em] \LARGE SAE821 -- Gérer un projet}

    \vspace{1.5cm}

    % Ligne de séparation
    \HRule
    \vspace{1cm}

    % Informations sur les auteurs
    \Large{Rapport de présenation de la modélisation d'un système de recommandation  respectant la vie privée}\\[0.5em]

    \vspace{1cm}
    \HRule\\[11cm]
    \begin{flushleft}
        \small
        \textbf{Pegliasco Matteo}\\
        \textbf{Berge Enzo}\\
        \textbf{Audouard Florian}\\
        \textbf{Hermelin Lois}\\
        \textbf{Master Informatique et Mathématiques}\\
        Université de Toulon, La Garde, Var, France
    \end{flushleft}
    \vfill

\end{titlepage}


\tableofcontents
\newpage

\section*{Introduction}
$ $\\
Ce rapport technique est un comtpe rendu dans le cadre de la SAE821 dont l'objectif est la conception et la modélisation d’un système de recommandation respectueux de la vie privée des utilisateurs. Les systèmes de recommandation sont aujourd’hui omniprésents dans de nombreux domaines, notamment sur les plateformes de commerce en ligne, les réseaux sociaux ou encore les services de streaming. Ils permettent d’orienter les utilisateurs vers des contenus pertinents en se basant sur l’analyse de leurs comportements et préférences.
Cependant, pour la majorité, ce traitement massif de données personnelles soulèvent des problématiques importantes liées à la protection de la vie privée, l'intégritée et la sécurité des données. Il est donc essentiel de réfléchir à des solutions techniques permettant de préserver la confidentialité des données tout en maintenant l’efficacité des recommandations.
L’objectif de ce projet est de modéliser un système de recommandation de films prenant en compte tout ces critères, en utilisant des méthodes préservant la protection des données utilisateurs. Ce rapport présentera les différentes étapes de la modélisation, les choix techniques réalisés, ainsi que les méthodes mises en œuvre pour concilier personnalisation et respect de la vie privée.

\section{Recherches théoriques}
\subsection{Systèmes de recommandation}
\subsubsection{Comprendre les Systèmes de Recommandation}
$ $\\
Les systèmes de recommandation sont devenus des outils incontournables au fils du temps. Ils permettent aux utilisateurs d'être dirigé vers des contenus pertinents et personnalisés parmi une mutilitude de choix, en s'appuyant sur des données comportementales, des préférences et des connaissances du contexte. Cette recherche retrace l'évolution des approches de recommandation, de leurs fondements les plus simples à des méthodes d'intelligence artificielle avancée, en s'appuyant sur l'article : \href{https://medium.com/@eliasah/delving-deeper-into-recommander-systems-from-basics-to-state-of-the-art-d92ee8e277f2}{ Delving Deeper into recommander Systems: From Basics to State-of-the-Art.}
\subparagraph{Evolution Chronologique}

\begin{itemize}
    \item Années 1990 - Premiers Modèles:

          \textbf{Le Filtrage Collaboratif (CF)} repose sur l'idée que des utilisateurs ayant patagé des préférences similaires dans le passé auront probablement des préférences semblables à l'avenir. Il existe deux variantes:
          \begin{itemize}
              \item \textbf{User-based CF: }recherche des utilisateurs similaires à l'utilisateur cible pour recommander les objets qu'ils ont aimés.
              \item \textbf{Item-based CF: }recherche des objets similaires à ceux déjà aimés par l'utilisateur pour proposer des recommandations
          \end{itemize}
          \textbf{Filtrage basé sur le Contenue (CB)} s'appuie uniquement sur les comportements passés de l'utilisateur, en particulier ses interactions avec certain objets. Contrairement au CF, il ne tient pas compte de la communauté mais des caractéristiques des élèments.
          \newline

    \item Années 2000 - Hybridation et Deep Learning:

          \textbf{Modèles hybrides} Ces modèles combinent CF et CB pour bénéficier de leurs avantages respectifs et une amélioration du démarrage à froid.

          \textbf{Début de l'apprentissage profond} L'arrivée du deep learning a introduit une nouvelle manière de représenter utilisateurs et objets à l'aide de réseaux de neurones capables d'extraire des caractéristiques complexes, non linéaires et profondes.
          \newline
    \item Années 2010 - Contexte et Connaissances:

          Les systèmes de \textbf{context-aware} prennent maintenant en compte des informations telles que le temps, la localisation, le dispositif utilisé ou encore l'état émotionnel.

          Les systèmes \textbf{knowledge-bases}, eux, utilisent des bases de connaissance et des bases de règles explicites pour mieux cerner les besoins utilisateurs, particulièrement utiles dans des cas de niches où les données sont rares.
          \newline
    \item Années 2020 - Intelligence Renforcée et Explicabilité:

          \textbf{La Recommandation par Apprentissage par Renforcement (RL)} permet une approche sequentille et interactive. Le système apprend à adapter ses recommandations en fonction des réactions de l'utilisateur. L'algorithme explore l'espace des solutions pour améliorer ses retours.

          \textbf{La Recommandation Explicable} fournit une justification compréhensible à l'utilisateur, améliorant ainsi la confiance et la transparence
\end{itemize}

\subparagraph{Types de Systèmes de recommandation:}
\begin{itemize}
    \item \textbf{Basé sur la mémoire}: Filtrage collaboratif simple
    \item \textbf{Basé sur un modèle}: Factorisation de matrice, réseaux de neurones, SVD
    \item \textbf{Basé sur le contenu}: utilisation des attributs des objets
    \item \textbf{Modèles hybrides}: Combine le filtrage collaboratif et filtrage basé sur le contenue
    \item \textbf{Apprentissage profond}: Réseaux de neurones
    \item \textbf{Système Contextuels}: Tiennent compte du contexte d'utilisation
    \item \textbf{Basé sur les connaissances}: Utilisent des logiques de règles, des bases de fait et ontologies
    \item \textbf{Apprentissage par renforcement}: Tiennent compte d'une interaction avec le client
    \item \textbf{Explicabilité}: Fournit une approche plus transparantes
    \item \textbf{Mutimodalité}: Combines plusieurs types de données
    \item \textbf{Protection de la vie Privée}: Utilise des techniques pour définir une forme de protection des résultats de requêtes
\end{itemize}

\subparagraph{Méthodes Avancées: }

\begin{enumerate}
    \item \textbf{Filtrage Collaboratif avec ALS} (Alternating Least Squares) :
          Repose sur le fait que deux utilisateurs ayant eu des opinions similaires auront des opinions similaires ans d'autres situations. Utilise la factorisation de matrice avec une méthode d'optimisation par moindrers carrés alternés.
    \item \textbf{Singular Value Decomposition} (SVD):

          Utilisation d'une matrice de notes \(R = (utilisateur*items)\), le SVD la décompose comme : \(R \approx U . \sum .
          V^t\)

          \begin{itemize}
              \item U = matrice des facteurs latents utilisateur
              \item \(\sum=\) matrice diagonal des valeurs singulières
              \item \(V^t=\) transposé de la matrice des facteurs latents des items
          \end{itemize}
          SVD version recommandation:

          Factorisation de la Matrice \(\hat{R}_{ui} = P_u^T Q_i \)
          \newline
          \( R_{ui} = \) note prédite par l'utilisateur \(u\) pour l'item \(i\)
          \newline
          \(P_u = \) vecteur latent de l'utilisateur \(u\) (préférences)
          \newline
          \(Q_i = \) note vecteur latent de l'item\(i\) (caractéristiques)
          \newline
          Le produit scalaire donne la note préditque de \(u\) donnerait à \(i\).

          Apprentissage de \(P\) et \(Q\): \[ \min_{P, Q} \sum_{(u,i) \in K} \left( R_{ui} - P_u^T Q_i \right)^2 + \lambda \left( \lVert P_u \rVert^2 + \lVert Q_i \rVert^2 \right)\]

          Avec \(K\) l'ensemble des paires utilisateur-item connues (données d'entraînement), \(R_{ui}\) note réelle et \(\lambda\) le coefficient de régularisation

    \item \textbf{Recurrent Neural Network} (RNN):

          Le réseau de neurones permet de traiter des séquences (texte, audio, clics, utilisations ...) Il possède une mémoire interne (qui utilise l'info précédente à chaque étape) et gère les dépendances temporelles.

          À chaque instant (t), le RNN reçoit une entrée \((x_t)\) et un état caché précédent \((h_{t-1})\), puis il calcule:
          \begin{itemize}
              \item L'État caché: \(h_t = \tanh(W_h h_{t-1} + W_x x_t + b)\)
              \item  La Sortie: \(y_t = \text{softmax}(W_y h_t + b_y)\)
          \end{itemize}
          Avec :\\
          - \( h_t \) = état caché (mémoire interne) à l’instant \( t \)\\
          - \( x_t \) = entrée à l’instant \( t \)\\
          - \( y_t \) = sortie prédite à l’instant \( t \)\\
          - \( W_h, W_x, W_y \) = matrices de poids\\
          - \( b, b_y \) = biais\\
          - \( \tanh \) = fonction d’activation\\
          - \( \text{softmax} \) = utilisée pour une prédiction de classe\\

    \item \textbf{ConvNet} (CNN):\\
          Modèle de traitement spation de données (image, audio, vidéos):
          \begin{itemize}
              \item \textbf{Convolutions:} Extraction de caractéristiques locales
              \item \textbf{Pooling:} Reduction dimensionnelle
              \item \textbf{Fattening:} Prise de décision finale
          \end{itemize}

    \item \textbf{Multi-Armed Bandit: }\\
          Approche d'apprentissage par renforcement, visant à maximiser les gains et explorer l'espace d'action tout en exploitant les meilleures options (permet de recommander tout en testant de nouvelles options).


\end{enumerate}

\subsubsection{Filtrage collaboratif}
$ $\\
Le filtrage collaboratif est une méthode de recommandation qui repose sur l’exploitation des interactions passées entre les utilisateurs
et les objets.
Contrairement au filtrage basé sur le contenu, il ne nécessite aucune information sur les caractéristiques des objets recommandés.

\subparagraph{Fonctionnement}
\begin{enumerate}
    \item \textbf{Collecte de données} : Récupération des interactions entre utilisateurs et objets, sous forme explicite (notes, avis) ou implicite (clics, temps passé, etc.).

    \item \textbf{Construction de la matrice utilisateur-objet} : Création d’une matrice où les lignes représentent les utilisateurs, les colonnes les objets, et les cellules contiennent les interactions.

    \item \textbf{Mesure de similarité} : Calcul de la similarité entre utilisateurs (user-based) ou entre objets (item-based) à l’aide de fonctions telles que la similarité cosinus ou le coefficient de corrélation de Pearson.

    \item \textbf{Prédiction} : Estimation de la préférence d’un utilisateur pour un objet non encore évalué, en se basant sur les préférences des utilisateurs ou objets similaires.

    \item \textbf{Génération de recommandations} : Sélection des objets les plus susceptibles d’intéresser l’utilisateur cible.
\end{enumerate}

\subparagraph{Exemple illustratif}
Considérons la matrice suivante représentant les notes de films par trois utilisateurs :

\begin{center}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
                      & Film A & Film B & Film C & Film D \\
        \hline
        Utilisateur 1 & 5      & ?      & 4      & 2      \\
        \hline
        Utilisateur 2 & 4      & 3      & 5      & 1      \\
        \hline
        Utilisateur 3 & 2      & 4      & 1      & 5      \\
        \hline
    \end{tabular}
\end{center}

Ici, le système peut prédire la note que l'utilisateur 1 donnerait au \textit{Film B}, en se basant sur les préférences des utilisateurs 2 et 3, jugés similaires selon leurs comportements passés.

\subparagraph{Avantages}
\begin{itemize}
    \item \textbf{Pas besoin de métadonnées} : Il peut fonctionner sans connaître les caractéristiques des objets à recommander.
    \item \textbf{Recommandations personnalisées} : Il permet de proposer des contenus pertinents et parfois inattendus grâce à l’analyse des préférences collectives.
    \item \textbf{Adaptabilité} : Le système évolue avec les comportements des utilisateurs, ce qui le rend dynamique.
\end{itemize}

\subparagraph{Inconvénients}
\begin{itemize}
    \item \textbf{Problème du démarrage à froid (cold start)} : Difficile de faire des recommandations précises pour un nouvel utilisateur ou un nouvel objet sans historique d'interactions.
    \item \textbf{Sparsité des données} : Les matrices utilisateur-objet sont souvent très clairsemées, ce qui complique la détection de similarités fiables.
    \item \textbf{Dépendance au comportement collectif} : Il peut recommander des objets peu pertinents si les utilisateurs similaires ont des goûts trop différents ou incohérents.
\end{itemize}

\subparagraph{Applications}
\begin{itemize}
    \item \textbf{Divertissement} : Netflix, Spotify pour recommander des films ou de la musique.
    \item \textbf{E-commerce} : Amazon pour proposer des produits selon les comportements d’achat d’utilisateurs similaires.
    \item \textbf{Éducation} : Recommandation de cours ou ressources pédagogiques.
    \item \textbf{Réseaux sociaux} : Suggestion de contacts, contenus ou groupes.
\end{itemize}

\subsubsection{Factorisation de matrice}
$ $\\
La factorisation de matrice \cite{matrix_fac} est une technique de recommandation user-based qui approxime les préférences des utilisateurs par le produit de deux matrices de plus
faible dimension. Ces matrices représentent des caractéristiques latentes des utilisateurs et des items — ici, les films. Comme évoqué précédemment, cette approximation peut être
obtenue à l’aide de l’algorithme des moindres carrés alternés ou de la descente de gradient stochastique .
Cette méthode est particulièrement adaptée aux systèmes de recommandation car elle s’applique efficacement à de grands ensembles de données, gère bien la sparsité des notations, et
peut être étendue pour intégrer des informations supplémentaires (comme des métadonnées ou du contenu).\\
\\
\underline{Par exemple :}\\
\\
Considérons une matrice de notes \( R \) représentant les notes données par 2 utilisateurs à 4 films :\\
\[R =
    \begin{bmatrix}
        5 & 3 & 0 & 1 \\
        4 & 0 & 0 & 1 \\
    \end{bmatrix}
\]
\\
où \( R_{ij} \) est la note donnée par l'utilisateur\( i \) au film \( j \), et  représente une note manquante.\\
L'objectif de la factorisation est donc d'approcher \( R \) par le produit de deux matrices : \(R \approx U \cdot V\).
En partant de deux matrices de tailles arbittraire est en corrigeant les erreurs, on peut obtenir une approximation de la matrice de notes \( R \) comme :\\
\[
    R \approx
    \begin{bmatrix}
        1.5 & 0.5 \\
        1.2 & 0.4 \\
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
        3.0 & 1.5 & 0.5 & 0.2 \\
        1.0 & 1.0 & 0.2 & 0.5 \\
    \end{bmatrix}
    =
    \begin{bmatrix}
        5.00 & 2.75 & 0.85 & 0.55 \\
        4.00 & 2.20 & 0.68 & 0.44 \\
    \end{bmatrix}
\] $ $\\
Avec cette factorisation, la méthode prédit alors que l'utilisateur 1 donnerait une note
proche de 0.85 au troisième film et l'utilisateur 2 donnerait une note provhe de 0,2.\\
Toutefois, cette approche présente certaines limites. Tout d'abord, elle nécessite une étude
profonde de ses hyperparamètres pour obtenir des résultats pertinents, notamment le nombre de
facteurs latents à utiliser. De plus, elle est sensible au problème du démarrage à froid pour
les nouveaux utilisateurs ou items -films dans le cas présent- et a un coût de calcul qui peut
devenir important selon la taille du jeu de données.

\subsection{Système de recommandation à froid}
$ $\\
Au fil du temps, plusieurs approches ont été développées pour répondre aux problèmes de recommandation à froid,
c’est-à-dire lorsqu’il s’agit de recommander de nouveaux films ou de faire des suggestions à de nouveaux utilisateurs.
Parmi elles, on peut distinguer les principales suivantes :
\begin{itemize}
    \item \textbf{Les méthodes basées sur le contenu (content-based)}, comme présenté par Schein, A. I., Popescul, A., Ungar, L. H.,
          et Pennock, D. M. (2002) \cite{schein2002_methods}, utilisent les caractéristiques des items — ici,
          des films — comme la description, le genre ou les acteurs. En calculant la similarité entre les caractéristiques
          de films (par exemple avec la similarité cosinus), on peut recommander des films proches de ceux déjà appréciés
          par un utilisateur.
    \item \textbf{Les approches hybrides} combinent le filtrage collaboratif et le filtrage basé sur le contenu afin
          de bénéficier des avantages des deux. Par exemple et comme présenté par Xiaoyuan Su et Taghi M. Khoshgoftaar (2010) \cite{su_cf_survey}, plusieurs implémentation sont possible. Il est possible
          d'implémenter séparemment une méthode collaborative et une méthode basée sur le contenu, puis de combiner les résultats pour générer des recommandations
          plus pertinentes ou encore d'implémenter un modèle unifié, intégrant à la fois des caractéristiques du contenu et du filtrage collaboratif.
          L’ajout progressif d’interactions utilisateur permet ainsi d’améliorer la précision des recommandations.
    \item \textbf{Les méthodes basées sur le clustering} regroupent les utilisateurs ou les items selon leurs caractéristiques
          communes, comme présenté par Nguyen et al. (2024)\cite{nguyen2024_ere} ou encore Snider (2019) \cite{snider_unsupervised}.
          L'objectif de cette approche est de générer des recommandations en s’appuyant sur la structure des groupes formés en recommandant, par exemple ,
          un unique cluster de données pour limiter la diversité ou inversement en recommandant des films de plusieurs clusters pour la favoriser.
\end{itemize}

\subsection{Confidentialité}
\subsubsection{Chiffrement homomorphe}
$ $\\
Le chiffrement homomorphe est une technique de cryptographie qui permet d'effectuer des calculs sur des données chiffrées sans avoir besoin de les déchiffrer au préalable mais dont le résultat déchiffré conserve les opérations entre les données claires.
Pour cela, plusieurs catégories de chiffrements existent:\\
\begin{itemize}
    \item \textbf{Chiffrement partiellement homomorphe}: Il permet de réaliser des opérations sur des données chiffrées pour une loi spécifique, par exemple l'addition ou la multiplication entre des données chiffrées.
    \item \textbf{Chiffrement presque entièrement homomorphe}: Il permet de réaliser un nombres limité d'opérations sur des données chiffrées pour plusieurs lois spécifiques, par exemple l'addition et la multiplication entre des données chiffrées, à cause d'une accumulation de bruit.
    \item \textbf{Chiffrement entièrement homomorphe}: Il permet de réaliser un nombre illimité d'opérations sur des données chiffrées pour toutes les lois possibles, mais il est limité par la taille du bruit accumulé lors des opérations.
\end{itemize}
$ $\\
Dans le cadre de ce projet nous nous sommes intéressés particulièrement au chiffrement entièrement homomorphe pour sa flexibilité d'utilisation pour différents système de recommandations.\\
Ainsi, plusieurs approches existent pour la mise en place du chiffreemnt homomorphe: \\
\begin{itemize}
    \item \textbf{Chiffrement DGHV avec bootstrapping \cite{boots}}: Le chiffrement DGHV \cite{dghv} est un système de chiffrement homomorphe, opérant sur des entiers, basé sur le problème de la somme de sous-ensembles clairsemée et le problème du PGCD approché.
    \item \textbf{Chiffrement GSW avec bootstrapping\cite{boots}}: Le chiffrement GSW \cite{gsw} est un système de chiffrement homomorphe, opérant sur des bits, basé sur le problème de la factorisation des entiers et le problème du logarithme discret.
    \item \textbf{Chiffrement TFHE}: Le chiffrement TFHE \cite{tfhe} est un système de chiffrement homomorphe, opérant sur des bits, basé sur la version torique du problème Learning With Errors.
\end{itemize}
$ $\\
Toutefois, même si si le chiffrement homomorphe permet de préserver la confidentialité des données, leurs utilisations présentent plusieurs contraintes:
\begin{itemize}
    \item Les données chiffrées sont généralement plus volumineuses que les données claires, ce qui peut poser des problèmes de stockage et de transmission de données. Par exemple,
          dans l'article de I. Chillotti, N. Gama, M. Georgieva, et M. Izabachène. (2016) \cite{end_size} où on apprend en conclusion de l'article que la taille du texte chiffré est 400 000 fois plus grand que celui d'origine.
    \item L'utilisation de "bootstrapping" \cite{boots} pour limiter l'accumulation de bruit peut augmententer le temps de calcul avec un nombre d'opérations significatifs réalisées. En effet, servant de contrôle de la taille
    \item du bruit, les opérations de "bootstrapping" augmentent les opérations réalisées sur le texte chiffré, pouvant ainsi influer sur le temps de calcul.
          augmentent aussi le temps de calcul.
    \item La mise en place sans ressouces externes est complexe et les ressources externes - sans prendre en compte leurs fiabilités - sont principalement disponible avec des bibliothèques
          en C++ ou RUST, comme Microsoft SEAL, HElib ou PALISADE, ce qui complique l'interaction avec d'autres langages de programmation comme Java.
\end{itemize}

\subsubsection{Differential privacy}
$ $\\
La confidentialité différentielle est une approche qui vise à garantir la protection de la vie privée des individus dans les ensembles de données en restreignant la relation entre les données de sortie et les données de l'utilisateur.
Pour cela, plusieurs approches existent:\\
\begin{itemize}
    \item \textbf{Mécanisme exponentiel}: Le mécanisme exponentiel \cite{programming_dp} permet de sélectionner aléatoirement un élément parmi un ensemble de données, en favorisant les élèments ayant le plus de poids selon une fonction d'évaluation donnée.
    \item \textbf{Réponse aléatoire}: Le mécanisme de réponse aléatoire telle qu'utilisé dans le bulletin de psychologie écrit par de BEGIN G. et SAVARD F. \cite{psychologie} vise à brouiller les réponses données en remplaçant aléatoirement certaines réponses par des valeurs aléatoires.
          En connaissant la probabilité d'obtenir une valeur aléatoire, il est alors possible d'estimer la proportion de données réelles ainsi que la variance au sein des données.
    \item \textbf{\emph{K-anonymisation} et \emph{L-diversité}}: La \emph{K-anonymisation}\cite{kanonymisation} et la \emph{L-diversité} consistent à masquer les élèments de quasi-identification d'un
          individu en le regroupant avec $K-1$ autres individus dans une représentations plus large, tout en conservant la visibilité des $L$ informations spécifiques à chaque utilisateurs et destinées à être partagées.
    \item \textbf{Mécanisme de Laplace ou Gaussien}: Le mécanisme de Laplace ou Gaussien \cite{laplace&gauss} consiste à altérer les données des utilisateurs pour masquer les données réelles tout en conservant la répartition moyenne des données en ajoutant un bruit aléatoire.
\end{itemize}

\section{Démarche choisie}
\subsection{Motivations du choix}
\subsubsection{Confidentialité des données}
$ $\\
Le cadre de ce projet est de mettre en place un système de recommandation de films respectant la vie privée des utilisateurs. Nous avons
considéré que la base de données des utilisateurs ainsi que les films proposés pouvaient évoluer au fil du temps.
Pour la protection de la vie privée des utilisateurs, nous avions considéré l'utilisation du chiffrement homomorphe TFHE, mais
la complexité de son implémentation et de son utilisation, avec notamment l'interaction entre différents langages de programmation (Java, C++, RUST),
ainsi que la complexité de l'utilisation de l'apprentissage machine avec une bibliothèque spécialisée, nous a poussés à nous intéresser davantage à la confidentialité différentielle.\\
Plus précisément, nous nous sommes particulièrement intéressés à la mise en place du mécanisme de bruitage et du mécanisme exponentiel pour la mise
en place de la confidentialité différentielle pour, respectivement, les recommandations pour un nouvel utilisateur et les recommandations personnalisées
d'un utilisateur ayant déjà évalué une certaine quantité de films.\
En ce qui concerne le mécanisme de génération du bruit, nous avons choisi d'utiliser le mécanisme de Laplace pour masquer les données des utilisateurs.\
Ce choix est motivé par le contexte de ce projet. En effet, les utilisateurs peuvent modifier leur evaluation d'un film. Dans cet optique, et contrairement au
mécanisme gaussien, nous avons favorisé le mécanisme de Laplace car c'est un mécanisme $\epsilon$-indistinguable. C'est-à-dire qu'il garantit qu'une
modification d'une entrée dans une base de données crée une modification bornée de la distribution de probabilité.\
De plus, étant donné que la base de données initale possède relativement peu d'évaluation utilisateurs pour chaque film, le mécanisme de Laplace est privilégié
puisque la génération de bruit à forte valeur est moins probable que pour le mécanisme gaussien, dû à une distribution plus centré en 0 pour la courbe Laplacienne,
ce qui permet de garantir une meilleure précision dans l'étude de la moyenne des évaluations des films.\\
Enfin, dans le cadre d'une protection des données privée des utilisateurs, nous avons eu la volonté de limité l'utilisation de ressources externes
pour la génération des données bruitées afin de reposer au minimum sur la fiabilité de ces ressources et avoir un maximum de contrôle sur la génération de bruit (c.f 2.1.2 Analyse du bruit Laplacien). Ce faisant,
l'implémentation du mécanisme Gaussien impliquerait l'implémentation complexe, avec le temps disponible, de l'approximation de l'inverse de la fonction:
\begin{equation}
    F(x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}} dt
\end{equation}
afin de générer du bruit. Ainsi, nous avons privilégié l'implémentation plus simple du mécanisme de Laplace qui s’adapte mieux aux traitements
ponctuels sur des bases de données de taille variable, ccorrespondant aux besoins de notre système d'entraînement pour nos recommandations.\
En complément, et comme présenté précédemment, nous avons considéré l'utilisation du mécanisme exponentiel pour une sélection aléatoire biaisée d'un film recommandé.
Cette approche permet à la fois de favoriser certain films - ici ceux qui ont une note moyenne la plus éloigné de 2.5 pour recommander des films qui n'ont jamais été noté ou des
films avec une bonne notation - grâce à une fonction d'utilité définie dans le système, tout en limitant le risque que
l'utilisateur puisse extraire des informations individuelles sur les autres utilisateurs ayant permis de générer les recommandations avec une bonne
calibration.

\subsubsection{Analyse du bruit Laplacien}
$ $\\
Comme présenté plus tôt, la mise en place manuel du mécanisme de Laplace pour la génération de bruit permet un meilleure contrôle sur la génération du bruit. Cette section vise à présenter
les implications du choix des paramètres du mécanisme de Laplace pour la génération de bruit.\\
La génération du bruit de Laplace est basée sur la distribution de Laplace. Plus précisement, et comme mise en place dans le système en posant $b$ le budget de confiancialité, la génération du bruit de Laplace est définie par :
\begin{equation}
    Laplace(b) = b \cdot \text{sign}(x) \cdot \ln(1 - 2|x|)
    \label{eq:laplace}
\end{equation}
, où $x$ est un nombre aléatoire tiré de la distribution uniforme sur l'intervalle \( ]-0.5, 0.5[ \).\\
A partir de cette écriture, il est alors possible de définir la variance du bruit généré par le mécanisme de Laplace ainsi que de choisir le budget de confidentialité $b$ pour la génération du bruit avec que la
probabilité de génération de bruit supérieur à une certaine limite $L$ soit inférieur à un certain seuil $p$.\\

\textbf{Propriété 1:}\\
Soit $b>0$.\\
La variance fonctionnelle du bruit généré par le mécanisme de Laplace est donnée par : $2b^2$.\\

\textbf{Démonstration :}\\
Plaçons nous dans les conditions de l'énoncé.\\
La variance fontionnelle de la fonction $\phi : x\mapsto Laplace(b) $, noté $V(\phi)$, est donnée par : $ \int_{-0.5}^{0.5} (Laplace(b) - \overline{Laplace})^2 dx$, où $\overline{Laplace}$
est la moyenne de la fonction $\phi$ sur l'intervalle $]-0.5, 0.5[$.\\
                La fonction $\phi$ étant antisymétrique, on a alors que $V(\phi) = \int_{-0.5}^{0.5} Laplace(b) ^2dx =  \int_{-0.5}^{0.5} b^2\ln(1-2|x|)^2$.\\
                \\
                Par symétrie de la fonction $x\mapsto \ln(1-2|x|)$, on a que : $V(\phi) =  2b^2\int_{-0.5}^{0} \ln(1+2x)^2dx$.\\
                En posant $X = 1+2x$, on a alors que : $V(\phi) =  2b^2\int_{0}^{1} \frac{\ln(X)^2}{2}dX$.\\
                En utilisant l'intégration par parties, on a alors que : $V(\phi) = b^2([X\ln(X)]_0^1 - 2[X(\ln(X)-1)]_0^1)$.\\
                Par croissance comparée , on a alors que : $V(\phi) = 2b^2$.\\

                \textbf{Propriété 2:}\\
                Soient $p \in ]0, 1[$, $L > 0$ et $b>0$.\\
            $P( |Laplace(b)| > L) \leq p$ si et seulement si $b \leq \frac{-L}{\ln(p)}$.\\

                \textbf{Démonstration :}\\
                Plaçons nous dans les condition de l'énoncé.\\
                Sachant que l'évènement $(|Laplace(b)| > L)$ est équivalent à $(Laplace(b)<-L) \cup (Laplace(b)>L)$, on a alors que :
                \(P( |Laplace(b)| > L) = P(Laplace(b)<-L) + P(Laplace(b)>L) \) car les évènements sont disjoints.\\
                \\
                Comme $b>0$ par hypothèse et que $x\mapsto \ln(1 - 2|x|)$ est négative sur l'intervalle $]-0.5, 0.5[$, on a alors que :
                \( (Laplace(b)>L) \Leftrightarrow (-b \ln(1+2x)>L)\) et \( (Laplace(b)<-L) \Leftrightarrow (b \ln(1-2x)<-L)\). \\
                Ainsi: $ (Laplace(b)>L) \Leftrightarrow ( -b \ln(1+2x)>L) \Leftrightarrow (x < \frac{ e^{-L/b}-1}{2})$ avec $x\in]-0.5,0[$\\
Et : $ (Laplace(b)<-L) \Leftrightarrow ( b \ln(1-2x)<-L) \Leftrightarrow (x > \frac{ 1-e^{-L/b}}{2})$ avec $x\in]0,0.5[$.\\
\\
Par hypothèse, comme $x$ suit une une loi uniforme sur l'intervalle $]-0.5, 0.5[$, on a alors que :
\begin{align*}
    P(Laplace(b)>L) = \frac{ e^{-L/b}-1}{2} - (-0.5) = \frac{ e^{-L/b}}{2} \\
    P(Laplace(b)<-L) = 0.5 - \frac{ 1-e^{-L/b}}{2} = \frac{ e^{-L/b}}{2}
\end{align*}
Et donc : $P( |Laplace(b)| > L) = e^{\frac{-L}{b}}$.\\
On cherche $b$ tel que $P( |Laplace(b)| > L) \leq p$ et on a alors que : $e^{\frac{-L}{b}} \leq p \Leftrightarrow b \leq \frac{-L}{\ln(p)}$.\\
\\
Ainsi, avec une implementation manuelle du mécanisme de Laplace, il est alors possible de manipuler le budget confidentiel $b$ pour contrôler
la génèration de bruit tout en maximisant la variance du bruit généré pour augmenter la confidentialité des données. Pour cela, et en utilisant les deux propriétés précédentes,
le choix optimale du budget de confidentialité $b$ pour la génération du bruit est : $b = \frac{-L}{\ln(p)}$ avec $L$ la limite de bruit maximal souhaitée et $p$ le seuil de probabilité de génération de bruit supérieur à $L$.\\















\subsubsection{Modèles de recommandations}
$ $\\
Pour le système de recommandation, nous avons choisi de mettre en place deux approches pour la recommandation de films: un système se basant sur le SVD pour un
utilisateurs connus du système - individu ayant déjà noté un certain nombre de films - et un autre système de recommandation basé sur la clustering non supervisé
pour la recommandation à froid d’un nouvel utilisateur.\\
\begin{itemize}
    \item \textbf{Pour le SVD:} \\
          $ $\\
          Le système de recommandation à chaud mis en place repose sur une approche collaborative fondée sur la décomposition en valeurs singulières (SVD).
          Inspirée des travaux classiques en filtrage collaboratif, cette méthode permet de prédire les préférences d’un utilisateur connu du système, c’est-à-dire ayant déjà noté un certain nombre de films.

          \begin{enumerate}
              \item Construction de la matrice d’interactions : une matrice utilisateur–film est construite à partir des notes données par les utilisateurs.
                    Chaque ligne représente un utilisateur et chaque colonne un film, les entrées correspondant aux notes attribuées.

              \item Factorisation de la matrice : cette matrice est ensuite factorisée en trois sous-matrices :\\
                    \[ R \approx U \Sigma V^T \]
                    \begin{itemize}
                        \item \(U\) représente les facteurs latents des utilisateurs,
                        \item \(V\) les facteurs latents des films,
                        \item \(\Sigma\) une matrice diagonale contenant les valeurs singulières.
                    \end{itemize}
                    Cette décomposition permet d'identifier des facteurs implicites (préférences, styles, affinités thématiques) non directement observables dans les données brutes.
              \item Prédiction des notes : une fois les vecteurs latents appris, le système peut estimer la note qu’un utilisateur donnerait à un film non encore vu, en effectuant le produit scalaire entre les vecteurs latents correspondants.
                    Les films obtenant les meilleures prédictions peuvent alors être recommandés.
          \end{enumerate}
          $ $\\
          L’objectif de ce système de recommandation est donc, à la fois, de proposer des suggestions personnalisées aux utilisateurs connus du système,
          en exploitant les préférences implicites issues des notations passées, de maximiser la pertinence des recommandations en limitant la redondance,
          et de tirer parti des corrélations latentes entre utilisateurs et films pour améliorer la qualité globale des prédictions.
          $ $\\
        
    \item \textbf{Pour le système de clustering:}\\
          $ $\\
          Le système de recommandation à froid mis en place se base sur une recommandation item-based via un système de clustering, à l'image de Snider 2019 \cite{snider_unsupervised} et de la sélection aléatoire de films.
          Plus précisement, l'algotithme de recommandation se compose en trois étapes principales:\\
          \begin{enumerate}
              \item Sélection des films pouvant être recommandés selon certain critères. Dans notre implémentation, les films recommandables sont les films ayant une note moyenne supérieure ou égale à un seuil (ici, 3) ou
                    ayant un nombre d’évaluations inférieur ou égal à un seuil (ici, 0). Cette approche permet alors de recommander des films étant globalement appréciés par les utilisateurs l'ayant noté et donc de recommander des films qui
                    pourront plaire à l'utilisateur mais aussi de recommander des films peu notés pour obtenir plus d'informations statistiques sur ces films tout en favorisant la diversité des films recommandés.
              \item Clustering des films : Une fois nos films sélectionnés, des vecteurs de caractéristiques sont générés à partir de leurs informations descriptives. Ici, nous avons utilisé les genres et le synopsis des films ainsi que leurs dates de
                    sortie (année, jour et mois) pour générer un vecteur de caractéristiques. Pour générer le vecteur de caractéristiques des genres, respectivement du synopsis, dans le serveur Python, nous avons utiliser la fonction "MultiLabelBinarizer" de
                    la bibliothèque "sklearn" et la fonction "SentenceTransformer" de la bibliothèque Python "sentence\_transformers".\\
                    Après la normalisation de ces vecteurs, une réduction de dimension est appliquée (via l’algorithme UMAP) suivie d’un clustering non supervisé (DBSCAN) comme présenté par les tables en annexe \ref{tab:resultats_sb} \ref{tab:resultats_b} . L'utilisation de l'algorithme DBSCAN permet ainsi de regrouper
                    les films selon leur similarité - ici, la similarité cosinus - tout en offrant une meilleure adapation à l'évolution des films dans la base de données que des clusters supervisés.
              \item Sélection aléatoire de films : Afin de favoriser la diversité des films recommandés, le système sélectionne aléatoirement un cluster, puis, de manière biaisée pour favoriser les films avec la moyenne la plus faible (représentant les films sans évaluation), un film au sein de celui-ci.
                    Pour ce faire, nous avons utilisé une fonction d'utilité définie dans le système pour favoriser les films ayant une note moyenne la plus proche de 0, qui après le tri de l'étape 1, représente les films les moins notés.
          \end{enumerate}
          $ $\\
          L'objectif de ce système de recommandation vise donc, à la fois, de représenter la diversité des films dans la base de données, limiter la redondance des recommandations avec les choix aléatoires de clusters et de films, mais aussi de recommander des films
          ayant un certain intêret, ici les films appréciés en moyenne par les utilisateurs ou les films peu notés (car possiblement récent ou peu vu).\\
\end{itemize}

\subsection{Implémentation dans le système}
$ $\\
Cette partie sert à présenter l'implémentation de la démarche choisie dans le système de recommandation de films tout en résumant l'approche adoptée pour la mise en place de la confidentialité des données.\\
Ainsi pour implémenter ces différents élèments, nous avons structuré notre projet de la manière suivante:\\
\begin{itemize}
    \item Un serveur de base de données  PostgreSQL, implémenté en Java via le framework Quarkus, dédié au stockage des informations des films ainsi que les informations relatives aux utilisateurs.
    Dans un optique de performance dans le cadre d'une utilisation en production, ce serveur est relié à une couche de recherche rapide via une base de données NoSQL, elle aussi implémentée en Java, 
    qui permet d'augmenter la rapidité de réponse du système lors des recherches.
    \item Un serveur de recommandation, implémenté en Python, dédié aux recommandations à chaud et à froid. Il est relié au serveur de base de données pour récupérer les 
    informations nécessaires à la génération des recommandations via un transfert de fichiers CSV.
\end{itemize}
$ $\\
Plus précisement, notre implémentation nécessite l'initialisation de la base de données via une requête au serveur Python. À partir de cette requête, le serveur Python va alors 
récupérer les films ainsi que les évaluations stockées dans la base de données afin d'initialiser et d'entraîner les modèles de recommandation. Lors de cette étape et afin de garantir 
la confidentialité des données, les notes utilisateurs sont alors chiffrées avec le mécanisme de Laplace.\\
Par la suite, lors de la demande de recommandations pour un utilisateur, la base de données est interrogée pour obtenir le nombre d’évaluations données par celui-ci. Si l'utilisateur a 
un nombre de notes supérieur à un seuil (ici, 0), le système de recommandation à chaud est utilisé pour générer des recommandations personnalisées. Dans le cas contraire, le système de 
recommandation à froid est utilisé pour générer le double des recommandations demandées. Cette augmentation du nombre de recommandations vise, comme présenté précédemment, à garantir la 
confidentialité des données en sélectionnant aléatoirement la moitié des recommandations en privilégiant les films avec les notes moyennes les plus élevés ou les plus faiblesles films avec les notes moyennes les plus élevées ou les plus faibles 
(pour lequelle la note moyenne est fixée à 0).

\section{Résultats expérimentaux}
\subsection{Précision des recommandations et performance computationnelles}
\subsubsection{Système de recommandation à chaud}
$ $\\
L’évaluation de notre système de recommandation à chaud met en évidence des résultats satisfaisants, tant sur le plan de la qualité des suggestions que sur celui des performances techniques.

Sur le plan de la précision des recommandations , le modèle atteint un score de \textbf{72,2\%}, ce qui indique qu’une large majorité des élèments recommandés sont pertinents pour les utilisateurs. Le \textbf{rappel}, quant à lui, s’élève à \textbf{69,1\%}, traduisant la capacité du système à retrouver une part importante des élèments pertinents parmi l’ensemble de ceux disponibles. Ces résultats démontrent un bon équilibre entre exactitude et couverture, ce qui est crucial dans le contexte d’un système à chaud, où les préférences peuvent évoluer rapidement.

Concernant les performances computationnelles, les mesures effectuées montrent une \textbf{initialisation des données très rapide (0,14 seconde)}, suivie d’une \textbf{entraînement du modèle en 0,72 seconde}, ce qui reste tout à fait raisonnable dans un usage en ligne ou en quasi temps réel. Le \textbf{temps de réponse moyen aux requêtes} est particulièrement bas, avec une valeur de \textbf{0,03 seconde}, garantissant une expérience fluide et réactive pour l’utilisateur.

Ces résultats confirment l’efficacité du modèle SVD employé dans un cadre de recommandations à chaud, capable de fournir des suggestions pertinentes tout en maintenant une latence très faible.

\subsubsection{Système de recommandation à froid}
$ $\\
Pour les systèmes de recommandation à froid, les notions de précision et de rappel ne sont pas adaptées,
car le système ne dispose pas d'informations sur les préférences des utilisateurs. Il ne peut donc pas
prédire quels films seraient pertinents pour eux. Notre objectif avec ce type de système se centre principalement 
sur la représentation de la diversité des films présents dans la base de données, tout en limitant la
redondance des recommandations et en mettant en avant des films peu notés ou bien évalués.\\
Ainsi, nous avons choisi d'évaluer la qualité des recommandations à l'aide des métriques suivantes :\\
\begin{itemize}
    \item Le nombre de clusters différents présents dans les recommandations pour un utilisateur.
    \item Le nombre de films distincts recommandés par utilisateur.
    \item Le pourcentage de films sans évaluation (i.e., n'ayant aucune note) recommandés.
    \item La diversité des genres des films recommandés.
\end{itemize}
$ $\\

Par ailleurs, afin de comparer les performances des systèmes de recommandation à froid selon la méthode de
réduction de dimension utilisée, nous avons également analysé les temps d’initialisation, d’entraînement
et de réponse du système. Pour effectuer ces mesures — visibles dans les tableaux « Résultats expérimentaux
du système de recommandation à froid sans bruit » (Tableau~\ref{tab:resultats_sb}) et « Résultats expérimentaux
du système de recommandation à froid avec bruit » (Tableau~\ref{tab:resultats_b}) — nous avons utilisé une même
graine aléatoire pour la génération des clusters et réalisé 609 tests pour chaque configuration de réduction de dimension avec une demande recommandation de 20 films.
Ces deux tableaux présentent les métriques suivantes :\\
\begin{itemize}
    \item La dimension des vecteurs après réduction de dimension : \textbf{k}
    \item Le nombre de clusters différents présents dans les recommandations pour un utilisateur : \textbf{Clusters}
    \item Le ratio des genres recommandés par rapport à ceux présents dans la base de données : \textbf{Genre Div.}
    \item Le ratio des genres recommandés par rapport à ceux effectivement recommandables : \textbf{Inner Div.}
    \item Le ratio de films peu notés (n'ayant aucune note dans notre implémentation) parmi les films recommandés : \textbf{0 Cov.}
    \item Le taux de couverture des recommandations sur les films éligibles : \textbf{Cov.}
    \item Le nombre moyen de films distincts recommandés par utilisateur : \textbf{Mov./User}
    \item Le nombre moyen de clusters distincts recommandés par utilisateur : \textbf{Clust/User}
    \item Le nombre moyen de films recommandés ayant peu de notes : \textbf{0 Mov./Reco}
    \item Le temps de réponse moyen du système de recommandation : \textbf{Resp. Time}
    \item Le temps moyen d’initialisation du système : \textbf{Init.}
    \item Le temps moyen d’entraînement du système : \textbf{Train.}
\end{itemize}
$ $\\
A partir des résultats obtenus, nous avons pu observer que les approches de réduction de dimension permettent une meilleure séparation des films, avec une augmentation significative du nombre de clusters, passant de 2 (sans réduction) à environ 10 en moyenne (avec réduction), 
une meilleure représentation de la diversité des genres recommandés, de la diversité des films peu noté recommandés ainsi qu'une augmentation du nombre de films peu noté recommandé, d'environ respectivement 28\% , 352\% et de 58\% pour les données bruité avec réduction par rapport à celles sans réduction.\\. 
En revanche, l'approche sans réduction semble permettre une meilleure diversité de recommandations des films, avec une représentation d'environ 73\% en moyenne des films recommandables contre environ 22\% avec la réduction de dimension en moyenne (colonne « Cov. »). Cette augmentation de la couverture des films 
impacte aussi la redondance des recommandations, avec un nombre moyen de films distinctsrecommandés par utilisateur passant de 8 (sans réduction) à environ 2 (avec réduction), visible au travers de la colonne « Mov./User ».\\
De plus, le temps d’entraînement, bien que variable, augmente avec la réduction de dimension (environ 147 secondes en moyenne avec bruit, contre 101 secondes sans réduction). Les temps d’initialisation et de réponse restent très faibles dans tous les cas.
Ainsi, afin de favoriser au maximum la représentation de la diversité de la base de données, nous nous sommes concentrés sur les approches avec une réduction de dimensions, car elles semblent offrir un meilleur compromis entre la diversité des recommandations et la performance du système.\\
\\
Nous constatons alors que les performances du système de recommandation à froid sont relativement stables entre les données bruitées, avec un budget de confidentialité fixé à $b = 0.5 \approx \frac{-1}{\ln(0.1)}$, et les données non bruitées.. Dans
la suite, nous nous concentrons sur les résultats obtenus avec bruit, car ce sont les données qui sont utilisées dans le système pour les recommandations.\\
Le tableau « Résultats expérimentaux du système de recommandation à froid avec bruit » (Tableau~\ref{tab:resultats_b}) confirme la stabilité des performances
du système, comme en témoignent les faibles variances des métriques analysées.\\
\\
Globalement, le système montre une certaine redondance dans ses recommandations, avec un nombre moyen de films distincts recommandés d’environ 2 par utilisateur pour 20 films. En revanche, il parvient à une
diversité efficace de genres, avec une couverture moyenne d’environ 60\% des genres présents dans la base de données.
La représentation des clusters est également satisfaisante, avec en moyenne 9 à 11 clusters différents représentés dans
les recommandations, soit une couverture proche des 10 clusters moyen extraits lors du clustering.\\
Enfin, environ 23\% des films recommandés n’ont reçu aucune évaluation, ce qui équivaut à environ 4 films peu notés par recommandation, ce qui montre donc la mise en avant de contenus peu explorés.\\

\subsection{Limites et perspectives}
\subsubsection{Système de recommandation à chaud}
$ $\\
Malgré ses performances encourageantes, le système de recommandation à chaud présente plusieurs limites inhérentes à sa nature et à son fonctionnement.

Tout d’abord, la dépendance aux données récentes peut entraîner une instabilité des recommandations lorsque les préférences des utilisateurs évoluent rapidement ou de manière erratique. En effet, le système s’appuie essentiellement sur les interactions les plus récentes, ce qui peut conduire à une surexposition d’élèments populaires temporairement, au détriment de la diversité et de la découverte.

Ensuite, la méthode SVD utilisée dans ce contexte, bien que performante, repose sur des hypothèses linéaires et peut rencontrer des difficultés à modéliser des interactions complexes ou non linéaires entre utilisateurs et items. Cela limite potentiellement la capacité du système à capturer certaines nuances des préférences des utilisateurs.

De plus, les systèmes à chaud exigent une mise à jour rapide et fréquente des modèles pour rester pertinents, ce qui peut engendrer une charge computationnelle non négligeable dans des environnements à très grande échelle ou en présence de flux de données massifs.

Enfin, la qualité des recommandations reste fortement dépendante de la quantité et de la qualité des données disponibles. En cas de démarrage avec peu de données (problème du démarrage à froid) ou en présence d’utilisateurs peu actifs, les performances du système peuvent fortement diminuer.

Ces limites invitent à envisager des améliorations possibles, comme l’intégration de modèles hybrides, l’incorporation de filtres basés sur le contenu, ou encore l’optimisation des stratégies de mise à jour afin d’équilibrer précision, diversité et performance.

\subsubsection{Système de recommandation à froid}
$ $\\
Le système de recommandations à froid mis en place dans ce projet présente plusieurs limites.
Tout d’abord, il repose sur la sélection aléatoire de films au sein des clusters. Ainsi, lorsque
le nombre de films à recommander augmente, la probabilité que certain clusters ne soient pas sélectionnés diminue.\\
Pour répondre aux demandes de recommandations en petit nombre tout en assurant une certaine diversité, il serait pertinent
de sélectionner un film par cluster lors des premières suggestions, en suivant des règles spécifiques. Par exemple, on
pourrait privilégier les clusters les plus importants. Cela permettrait de garantir une représentation minimale de l’ensemble
de la base de données tout en assurant la diversité des recommandations.\\
\\
Ensuite, comme mentionné précédemment, le système de recommandations à froid repose sur une représentation
vectorielle des caractéristiques des films. Toutefois, afin de mieux adapter cette représentation
à une base de données spécifique d’utilisateurs, il serait intéressant d’y intégrer des
statistiques globales telles que le nombre d’évaluations, une approximation de la note moyenne
et la variance des notes pour chaque film. Cette approche pourrait enrichir la représentation
des films en tenant compte de leur réception par les utilisateurs, et ainsi permettre une recommandation plus pertinente.\\
\\
Enfin, approfondir l'analyse des performances du système de recommandations à froid en augmentant le budget de confidentialité
pourrait permettre de mieux évaluer l'impact du bruit sur la diversité des recommandations ainsi que sur la précision des recommandations.

\subsubsection{Mécanisme de Laplace}
$ $\\
Comme nous l’avons vu dans la section 2.1.2, il est possible de contrôler la génération du bruit dans le mécanisme de Laplace.
Toutefois, celle-ci est indépendante du nombre de données à protéger pour un film donné. Un bruit important tend à avantager les
films ayant un grand nombre d’évaluations, tout en défavorisant ceux qui en ont peu, rendant alors difficile l’extraction d’informations
statistiques pertinentes. Par exemple, en observant l’écart moyen du bruit généré par l’algorithme \ref{lst:laplace} (présenté en annexe),
avec un budget de confidentialité $b= \frac{-1}{\ln(0.9)}$, on peut obtenir environ 6,5 points d’écart par rapport à zéro pour 10
évaluations, contre seulement -0,1 pour 10 000 évaluations. Au contraire, en prenant $b= \frac{-0.5}{\ln(0.2)}$ , on peut obtenir environ
0.5 point d’écart par rapport à zéro pour 10 évaluations, contre seulement -0.0005 pour 10 000 évaluations\\
Dans ce projet, notre approche repose sur l’utilisation d’un budget de confidentialité faible, afin de garantir une étude statistique
fidèle aux données réelles, quel que soit le nombre d’évaluations d’un film. Cette stratégie est adaptée à une base de données avec
peu d’évaluations, comme MovieLens, où le nombre maximal de notes pour un film est de 329. En revanche, dans une base comportant un volume
beaucoup plus important, un bruit trop faible pourrait permettre une extraction probabiliste des données sensibles.\\
\\
Dans cette optique, il serait intéressant d’envisager la mise en place d’un budget de confidentialité variable, ajusté en fonction du nombre d’évaluations
par film et d'étudier la compatibilité d'une telle approche avec les systèmes de recommandation.

\subsubsection{Mécanisme exponentiel}
$ $\\
Dans ce projet, le mécanisme exponentiel a été mis en place afin d’ajouter un niveau de confidentialité côté interface utilisateur, limitant
ainsi le risque que les habitudes de consommation d'autres utilisateurs puissent être déduites. Toutefois, l’implémentation de ce mécanisme
augmente le temps de génération des recommandations, car il est nécessaire de recalculer les probabilités de sélection pour chaque film à chaque itération.\\
\\
Ainsi, il serait intéressant d’étudier des optimisations du mécanisme exponentiel permettant de réduire ce temps de calcul tout en conservant les garanties
de confidentialité. Une autre piste serait l’implémentation d’un système de préchargement des recommandations, afin de limiter le temps de réponse côté interface utilisateur.

\subsection{Résumé}




\newpage
\begin{thebibliography}{99}

    \bibitem{psychologie}
    J.-P. Rolland, « La technique de la réponse aléatoire : un moyen de contrôler la désirabilité sociale dans la mesure de l'estime de soi », \emph{Bulletin de Psychologie}, vol. 33, no. 343, 1979. [En ligne]. Disponible : \url{https://www.persee.fr/doc/bupsy_0007-4403_1979_num_33_343_1128} [Consulté le 28 mai 2025].

    \bibitem{schein2002_methods}
    A. I. Schein, A. Popescul, L. H. Ungar, et D. M. Pennock, « Methods and Metrics for Cold-Start recommandations », in \emph{Proc. 25th Annu. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr. (SIGIR '02)}, 2002, pp. 253–260. [En ligne]. Disponible : \url{https://www.researchgate.net/publication/221300490_Methods_and_Metrics_for_Cold-Start_recommandations} [Consulté le 28 mai 2025].

    \bibitem{kanonymisation}
    Wikipedia, « K-anonymisation », 2006. [En ligne]. Disponible : \url{https://fr.wikipedia.org/wiki/K-anonymisation} [Consulté le 28 mai 2025].

    \bibitem{su_cf_survey}
    X. Su et T. M. Khoshgoftaar, « A Survey of Collaborative Filtering Techniques », \emph{IEEE Trans. Knowl. Data Eng.}, vol. 22, no. 1, pp. 107–117, 2010. [En ligne]. Disponible : \url{https://pages.stern.nyu.edu/~atuzhili/pdf/TKDE-Paper-as-Printed.pdf} [Consulté le 28 mai 2025].

    \bibitem{laplace&gauss}
    C. Dwork et A. Roth, \emph{The Algorithmic Foundations of Differential Privacy}, Found. Trends Theor. Comput. Sci., vol. 9, no. 3–4, pp. 211–407, 2014. [En ligne]. Disponible : \url{https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf} [Consulté le 28 mai 2025].

    \bibitem{end_size}
    I. Chillotti, N. Gama, M. Georgieva, et M. Izabachène, « Faster Fully Homomorphic Encryption: Bootstrapping in Less Than 0.1 Seconds », \emph{Cryptology ePrint Archive}, Rapport 2016/870, 2016. [En ligne]. Disponible : \url{https://eprint.iacr.org/2016/870} [Consulté le 28 mai 2025].

    \bibitem{snider_unsupervised}
    G. Snider, « Unsupervised Product Clustering: Exploring the Cold Start Problem », \emph{SSENSE Tech Blog}, Medium, 2019. [En ligne]. Disponible : \url{https://medium.com/ssense-tech/unsupervised-product-clustering-exploring-the-cold-start-problem-8053ef04bac9} [Consulté le 28 mai 2025].

    \bibitem{matrix_fac}
    E. Azar, « Deep Dive into Matrix Factorization for recommander Systems: From Basics to Implementation », Medium, 2020. [En ligne]. Disponible : \url{https://medium.com/@eliasah/deep-dive-into-matrix-factorization-for-recommander-systems-from-basics-to-implementation-79e4f1ea1660} [Consulté le 28 mai 2025].

    \bibitem{dghv}
    E. Goblé et R. Gatelier, « Le chiffrement DGHV », Université de Technologie de Compiègne. [En ligne]. Disponible : \url{https://www.utc.fr/~wschon/sr06/tx_chiffrement_homomorphe/pages/dghv.html} [Consulté le 28 mai 2025].

    \bibitem{gsw}
    E. Goblé et R. Gatelier, « GSW », Université de Technologie de Compiègne. [En ligne]. Disponible : \url{https://www.utc.fr/~wschon/sr06/tx_chiffrement_homomorphe/pages/vecteurs_propres_approx.html} [Consulté le 28 mai 2025].

    \bibitem{boots}
    E. Goblé et R. Gatelier, « Le Bootstrap », Université de Technologie de Compiègne. [En ligne]. Disponible : \url{https://www.utc.fr/~wschon/sr06/tx_chiffrement_homomorphe/pages/bootstrapping.html} [Consulté le 28 mai 2025].

    \bibitem{programming_dp}
    \emph{Programming Differential Privacy}, « Chapter 9 — Fully Homomorphic Encryption (FHE) ». [En ligne]. Disponible : \url{https://programming-dp.com/ch9.html} [Consulté le 28 mai 2025].

    \bibitem{tfhe}
    B. Chandran, A. Ghoshal, S. Halevi, S. Ranellucci, et N. P. Smart, « Faster Homomorphic Comparison Operations for BGV and BFV », \emph{Cryptology ePrint Archive}, Rapport 2023/958, 2023. [En ligne]. Disponible : \url{https://eprint.iacr.org/2023/958} [Consulté le 28 mai 2025].

    \bibitem{nguyen2024_ere}
    Q. Nguyen, M. Naghiaei, et Y. Zhang, « Cold-start recommandation by Personalized Embedding Region Elicitation », \emph{arXiv preprint} arXiv:2406.00973, 2024. [En ligne]. Disponible : \url{https://arxiv.org/abs/2406.00973} [Consulté le 28 mai 2025].

\end{thebibliography}

\newpage
\section*{Annexes}
\addcontentsline{toc}{section}{Annexes}

\begin{lstlisting}[language=Python, caption={Fonction de génération de bruit Laplacien}, label={lst:laplace}]
def sign(x):
    if x >= 0:
        return 1
    elif x < 0:
        return -1

def laplace(b):
    x = random.uniform(-0.5, 0.5)
    return b * sign(x) * math.log(1 - 2 * abs(x))

def average_noise(b, n_test):
    total_noise = 0
    for _ in range(n_test):
        total_noise += laplace(b)
    return total_noise / n_test 
\end{lstlisting}


\begin{sidewaystable}[h!]
    \centering
    \caption{Résultats expérimentaux du système de recommandation à froid \textbf{sans bruit} ($b=0.5$, $20$ films recommandés, 609 tests par configuration)}
    \label{tab:resultats_sb}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
            \hline
            k                       & Clusters & Genre Div. & Inner Div. & 0 Cov.  & Cov.   & Mov./User & Clust/User & 0 Mov./Reco & Resp. Time (s) & Init (s) & Train (s) \\
            \hline
            \textbf{sans reduction} & 2        & 0.456      & 0.456      & 0.0025  & 0.703  & 8.057     & 2.0        & 0.044       & 0.0267         & 0.032    & 94.74     \\
            \hline
            50                      & 11       & 0.602      & 0.602      & 0.0104  & 0.206  & 2.363     & 9.422      & 0.187       & 0.0065         & 0.030    & 157.94    \\
            100                     & 10       & 0.602      & 0.602      & 0.0117  & 0.215  & 2.471     & 8.754      & 0.210       & 0.0071         & 0.016    & 157.40    \\
            150                     & 10       & 0.609      & 0.609      & 0.0130  & 0.230  & 2.634     & 8.874      & 0.235       & 0.0069         & 0.027    & 180.02    \\
            200                     & 12       & 0.575      & 0.575      & 0.0115  & 0.213  & 2.445     & 9.903      & 0.207       & 0.0075         & 0.018    & 189.72    \\
            250                     & 11       & 0.607      & 0.607      & 0.0120  & 0.230  & 2.634     & 9.368      & 0.217       & 0.0056         & 0.016    & 187.13    \\
            300                     & 11       & 0.565      & 0.565      & 0.0109  & 0.221  & 2.534     & 9.386      & 0.197       & 0.0054         & 0.015    & 201.89    \\
            350                     & 11       & 0.589      & 0.589      & 0.0074  & 0.189  & 2.163     & 9.455      & 0.133       & 0.0053         & 0.016    & 204.99    \\
            400                     & 10       & 0.578      & 0.578      & 0.0133  & 0.209  & 2.402     & 8.824      & 0.240       & 0.0071         & 0.018    & 223.61    \\
            \hline
            \textbf{Moyenne}        & 10.75    & 0.591      & 0.591      & 0.0113  & 0.214  & 2.456     & 9.248      & 0.190       & 0.0064         & 0.019    & 187.83    \\
            \textbf{Variance}       & 0.73     & 0.002      & 0.002      & 0.00004 & 0.0003 & 0.036     & 0.38       & 0.0011      & 0.0000007      & 0.00003  & 569.77    \\
            \hline
        \end{tabular}
    }
\end{sidewaystable}

\begin{sidewaystable}[h!]
    \centering
    \caption{Résultats expérimentaux du système de recommandation à froid \textbf{avec bruit} ($b=0.5$, $20$ films recommandés, 609 tests par configuration)}
    \label{tab:resultats_b}
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
            \hline
            k                       & Clusters & Genre Div. & Inner Div. & 0 Cov.   & Cov.   & Mov./User & Clust/User & 0 Mov./Reco & Resp. Time (s) & Init (s) & Train (s) \\
            \hline
            \textbf{sans reduction} & 2        & 0.466      & 0.466      & 0.0018   & 0.762  & 7.936     & 2.0        & 0.033       & 0.0325         & 0.031    & 100.69    \\
            \hline
            50                      & 10       & 0.603      & 0.603      & 0.0140   & 0.245  & 2.550     & 8.811      & 0.251       & 0.0042         & 0.014    & 111.17    \\
            100                     & 10       & 0.613      & 0.613      & 0.0119   & 0.248  & 2.583     & 8.824      & 0.213       & 0.0051         & 0.019    & 124.10    \\
            150                     & 10       & 0.604      & 0.604      & 0.0146   & 0.247  & 2.570     & 8.810      & 0.263       & 0.0050         & 0.014    & 125.55    \\
            200                     & 9        & 0.585      & 0.585      & 0.0136   & 0.256  & 2.667     & 8.209      & 0.245       & 0.0052         & 0.014    & 132.46    \\
            250                     & 10       & 0.598      & 0.598      & 0.0109   & 0.237  & 2.468     & 8.796      & 0.195       & 0.0055         & 0.013    & 170.78    \\
            300                     & 9        & 0.585      & 0.585      & 0.0135   & 0.245  & 2.552     & 8.141      & 0.243       & 0.0056         & 0.014    & 160.96    \\
            350                     & 12       & 0.607      & 0.607      & 0.0100   & 0.222  & 2.314     & 9.888      & 0.181       & 0.0042         & 0.013    & 166.62    \\
            400                     & 11       & 0.593      & 0.593      & 0.0121   & 0.218  & 2.271     & 9.450      & 0.218       & 0.0049         & 0.013    & 179.57    \\
            \hline
            \textbf{Moyenne}        & 10.13    & 0.598      & 0.598      & 0.0128   & 0.240  & 2.497     & 8.854      & 0.226       & 0.0050         & 0.014    & 146.90    \\
            \textbf{Variance}       & 0.99     & 0.001      & 0.001      & 0.000002 & 0.0002 & 0.021     & 0.38       & 0.0008      & 0.0000002      & 0.000004 & 682.13    \\
            \hline
        \end{tabular}
    }
\end{sidewaystable}
\end{document}
